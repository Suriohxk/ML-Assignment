{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":117504,"databundleVersionId":14083157,"sourceType":"competition"}],"dockerImageVersionId":31260,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2026-02-07T16:49:16.646675Z","iopub.execute_input":"2026-02-07T16:49:16.647013Z","iopub.status.idle":"2026-02-07T16:49:16.659590Z","shell.execute_reply.started":"2026-02-07T16:49:16.646984Z","shell.execute_reply":"2026-02-07T16:49:16.658892Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/binary-classification-with-a-bank-dataset-clone/sample_submission.csv\n/kaggle/input/binary-classification-with-a-bank-dataset-clone/train.csv\n/kaggle/input/binary-classification-with-a-bank-dataset-clone/test.csv\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"# ==========================\n# Load Data\n# ==========================\ntrain = pd.read_csv(\"/kaggle/input/binary-classification-with-a-bank-dataset-clone/train.csv\").drop('id', axis=1)\ntest = pd.read_csv(\"/kaggle/input/binary-classification-with-a-bank-dataset-clone/test.csv\").drop('id', axis=1)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-07T16:49:16.660937Z","iopub.execute_input":"2026-02-07T16:49:16.661202Z","iopub.status.idle":"2026-02-07T16:49:18.210167Z","shell.execute_reply.started":"2026-02-07T16:49:16.661183Z","shell.execute_reply":"2026-02-07T16:49:18.209608Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"import warnings\nimport optuna\n\nimport pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import StratifiedKFold, cross_val_score\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.feature_selection import mutual_info_classif\n\nimport xgboost as xgb\nimport lightgbm as lgb\n\nwarnings.filterwarnings('ignore')\noptuna.logging.set_verbosity(optuna.logging.WARNING)\n\nX = train.drop(columns=['y']).copy()\ny = train['y']\n\nfor col in X.select_dtypes(include='object'):\n    le = LabelEncoder()\n    X[col] = le.fit_transform(X[col])\n\nmi = mutual_info_classif(X, y, discrete_features='auto')\nmi_series = pd.Series(mi, index=X.columns).sort_values(ascending=False)\nprint(mi_series)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-07T16:49:18.211044Z","iopub.execute_input":"2026-02-07T16:49:18.211321Z","iopub.status.idle":"2026-02-07T16:50:30.106599Z","shell.execute_reply.started":"2026-02-07T16:49:18.211295Z","shell.execute_reply":"2026-02-07T16:50:30.105880Z"}},"outputs":[{"name":"stdout","text":"duration     0.154631\nhousing      0.120942\npoutcome     0.118989\nbalance      0.070033\ncontact      0.059184\nmarital      0.057853\neducation    0.056173\nmonth        0.053843\njob          0.033609\npdays        0.030757\ncampaign     0.024125\nage          0.018686\nday          0.014402\nloan         0.012775\nprevious     0.012011\ndefault      0.000999\ndtype: float64\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"def apply_feature_engineering(df):\n    df_fe = df.copy()\n    \n    label_encoders = {}\n    for col in df_fe.select_dtypes(include='object').columns:\n        if col != 'y':\n            le = LabelEncoder()\n            df_fe[col] = le.fit_transform(df_fe[col])\n            label_encoders[col] = le\n    \n    df_fe['poutcome_duration'] = df_fe['poutcome'] * df_fe['duration']\n    df_fe['housing_duration'] = df_fe['housing'] * df_fe['duration']\n    df_fe['poutcome_housing'] = df_fe['poutcome'] * df_fe['housing']\n    \n    df_fe['duration_per_campaign'] = df_fe['duration'] / (df_fe['campaign'] + 1)\n    df_fe['duration_log'] = np.log1p(df_fe['duration'])\n    df_fe['is_long_call'] = (df_fe['duration'] > df_fe['duration'].median()).astype(int)\n    \n    df_fe['job_duration_mean'] = df_fe.groupby('job')['duration'].transform('mean')\n    df_fe['job_age_mean'] = df_fe.groupby('job')['age'].transform('mean')\n    df_fe['job_balance_mean'] = df_fe.groupby('job')['balance'].transform('mean')\n    \n    df_fe['education_duration_mean'] = df_fe.groupby('education')['duration'].transform('mean')\n    df_fe['education_balance_mean'] = df_fe.groupby('education')['balance'].transform('mean')\n    \n    df_fe['marital_age_mean'] = df_fe.groupby('marital')['age'].transform('mean')\n    \n    df_fe['total_loans'] = df_fe['housing'] + df_fe['loan']\n    df_fe['financial_stress'] = (df_fe['default'] + df_fe['housing'] + df_fe['loan']).clip(0, 3)\n    \n    df_fe['contact_success_rate'] = df_fe['poutcome'] / (df_fe['previous'] + 1)\n    \n    df_fe['age_balance_ratio'] = df_fe['balance'] / (df_fe['age'] + 1)\n    \n    return df_fe\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-07T16:50:30.107459Z","iopub.execute_input":"2026-02-07T16:50:30.107712Z","iopub.status.idle":"2026-02-07T16:50:30.115488Z","shell.execute_reply.started":"2026-02-07T16:50:30.107692Z","shell.execute_reply":"2026-02-07T16:50:30.114960Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"train_fe = apply_feature_engineering(train)\ntest_fe = apply_feature_engineering(test)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-07T16:50:30.117457Z","iopub.execute_input":"2026-02-07T16:50:30.117661Z","iopub.status.idle":"2026-02-07T16:50:31.707475Z","shell.execute_reply.started":"2026-02-07T16:50:30.117644Z","shell.execute_reply":"2026-02-07T16:50:31.706713Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"X = train_fe.drop(columns=['y']).copy()\ny = train_fe['y']\n\nfor col in X.select_dtypes(include='object'):\n    le = LabelEncoder()\n    X[col] = le.fit_transform(X[col])\n\nmi = mutual_info_classif(X, y, discrete_features='auto')\nmi_series = pd.Series(mi, index=X.columns).sort_values(ascending=False)\nprint(mi_series)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-07T16:50:31.708461Z","iopub.execute_input":"2026-02-07T16:50:31.708777Z","iopub.status.idle":"2026-02-07T16:52:53.388171Z","shell.execute_reply.started":"2026-02-07T16:50:31.708745Z","shell.execute_reply":"2026-02-07T16:52:53.387489Z"}},"outputs":[{"name":"stdout","text":"duration_log               0.155157\nis_long_call               0.155091\nduration                   0.154517\npoutcome_duration          0.151345\nduration_per_campaign      0.145703\ncontact_success_rate       0.127087\nhousing                    0.120864\npoutcome                   0.119656\npoutcome_housing           0.112343\nmarital_age_mean           0.085463\neducation_duration_mean    0.078729\nhousing_duration           0.078319\nbalance                    0.069715\nfinancial_stress           0.069549\ntotal_loans                0.069228\neducation_balance_mean     0.066718\nage_balance_ratio          0.059430\ncontact                    0.058424\nmarital                    0.057723\neducation                  0.056240\nmonth                      0.054559\njob_age_mean               0.041661\njob                        0.034055\njob_balance_mean           0.030406\npdays                      0.029707\njob_duration_mean          0.028646\ncampaign                   0.024858\nage                        0.018754\nday                        0.014342\nloan                       0.012741\nprevious                   0.012316\ndefault                    0.001261\ndtype: float64\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"kf = StratifiedKFold(n_splits=5, shuffle=True)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-07T16:52:53.389230Z","iopub.execute_input":"2026-02-07T16:52:53.389504Z","iopub.status.idle":"2026-02-07T16:52:53.394651Z","shell.execute_reply.started":"2026-02-07T16:52:53.389475Z","shell.execute_reply":"2026-02-07T16:52:53.393802Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"def xgb_objective(trial):\n    params = {\n        'n_estimators': trial.suggest_int('n_estimators', 300, 1000),\n        'max_depth': trial.suggest_int('max_depth', 3, 12),\n        'learning_rate': trial.suggest_float('learning_rate', 0.001, 0.3, log=True),\n        'subsample': trial.suggest_float('subsample', 0.4, 1.0),\n        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.4, 1.0),\n        'colsample_bylevel': trial.suggest_float('colsample_bylevel', 0.4, 1.0),\n        'colsample_bynode': trial.suggest_float('colsample_bynode', 0.4, 1.0),\n        'min_child_weight': trial.suggest_int('min_child_weight', 1, 15),\n        'gamma': trial.suggest_float('gamma', 0.0, 1.0),\n        'reg_alpha': trial.suggest_float('reg_alpha', 0.0, 5.0),\n        'reg_lambda': trial.suggest_float('reg_lambda', 0.0, 5.0),\n        'tree_method': 'gpu_hist',\n        'use_label_encoder': False,\n        'eval_metric': 'logloss',\n        'verbosity': 0\n    }\n    model = xgb.XGBClassifier(**params)\n    score = cross_val_score(model, X, y, cv=kf, scoring='roc_auc', n_jobs=1).mean()\n    return score\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-07T16:52:53.395556Z","iopub.execute_input":"2026-02-07T16:52:53.395854Z","iopub.status.idle":"2026-02-07T16:52:53.422053Z","shell.execute_reply.started":"2026-02-07T16:52:53.395825Z","shell.execute_reply":"2026-02-07T16:52:53.421345Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"def lgb_objective(trial):\n    params = {\n        'n_estimators': trial.suggest_int('n_estimators', 200, 600),\n        'max_depth': trial.suggest_int('max_depth', 4, 12),\n        'num_leaves': trial.suggest_int('num_leaves', 30, 150),\n        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.2, log=True),\n        'subsample': trial.suggest_float('subsample', 0.6, 1.0),\n        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.6, 1.0),\n        'min_child_samples': trial.suggest_int('min_child_samples', 10, 100),\n        'reg_alpha': trial.suggest_float('reg_alpha', 0.0, 2.0),\n        'reg_lambda': trial.suggest_float('reg_lambda', 0.0, 2.0),\n        'device': 'gpu',\n        'objective': 'binary',\n        'metric': 'auc',\n        'verbosity': -1\n    }\n    model = lgb.LGBMClassifier(**params)\n    score = cross_val_score(model, X, y, cv=kf, scoring='roc_auc', n_jobs=1).mean()\n    return score\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-07T16:52:53.423080Z","iopub.execute_input":"2026-02-07T16:52:53.423285Z","iopub.status.idle":"2026-02-07T16:52:53.437900Z","shell.execute_reply.started":"2026-02-07T16:52:53.423262Z","shell.execute_reply":"2026-02-07T16:52:53.437206Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"def run_te_cvens_blending(train_data, test_data, submission_path, save_path, n_splits=10, xgb_model=None, lgb_model=None):\n    X = train_data.drop(columns=[\"y\"]).copy()\n    y = train_data[\"y\"]\n    \n    cat_cols = X.select_dtypes(\"object\").columns.tolist()\n    \n    kf = StratifiedKFold(n_splits=n_splits, shuffle=True)\n    CV_result = []\n    test_preds = []\n    \n    for fold, (train_idx, valid_idx) in enumerate(kf.split(X, y), 1):\n        X_train, X_valid = X.iloc[train_idx].copy(), X.iloc[valid_idx].copy()\n        y_train, y_valid = y.iloc[train_idx], y.iloc[valid_idx]\n        test_fold = test_data.copy()\n        \n        for col in cat_cols:\n            encoding_dict = y_train.groupby(X_train[col]).mean().to_dict()\n            global_mean = y_train.mean()\n            for category in X_train[col].unique():\n                n = (X_train[col] == category).sum()\n                smooth_mean = (encoding_dict.get(category, global_mean) * n + global_mean * 5) / (n + 5)\n                encoding_dict[category] = smooth_mean\n            X_train[col] = X_train[col].map(encoding_dict).fillna(global_mean)\n            X_valid[col] = X_valid[col].map(encoding_dict).fillna(global_mean)\n            test_fold[col] = test_fold[col].map(encoding_dict).fillna(global_mean)\n        \n        xgb_clf = xgb_model if xgb_model else xgb.XGBClassifier(use_label_encoder=False, eval_metric=\"logloss\")\n        lgb_clf = lgb_model if lgb_model else lgb.LGBMClassifier(objective=\"binary\", verbose=-1)\n        \n        xgb_clf.fit(X_train, y_train)\n        lgb_clf.fit(X_train, y_train)\n        \n        y_pred_proba = (xgb_clf.predict_proba(X_valid)[:, 1] + lgb_clf.predict_proba(X_valid)[:, 1]) / 2.0\n        CV_result.append({\"fold\": fold, \"roc_auc\": roc_auc_score(y_valid, y_pred_proba)})\n        \n        test_pred_fold = (xgb_clf.predict_proba(test_fold)[:, 1] + lgb_clf.predict_proba(test_fold)[:, 1]) / 2.0\n        test_preds.append(test_pred_fold)\n    \n    CV_result = pd.DataFrame(CV_result)\n    print(CV_result)\n    print(f\"Mean CV Score: {CV_result['roc_auc'].mean():.5f}\")\n    \n    y_test_pred_proba = np.mean(test_preds, axis=0)\n    submission = pd.read_csv(submission_path)\n    submission[\"y\"] = y_test_pred_proba\n    submission.to_csv(save_path, index=False)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-07T16:52:53.438625Z","iopub.execute_input":"2026-02-07T16:52:53.438891Z","iopub.status.idle":"2026-02-07T16:52:53.455165Z","shell.execute_reply.started":"2026-02-07T16:52:53.438862Z","shell.execute_reply":"2026-02-07T16:52:53.454401Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"xgb_tuned = xgb.XGBClassifier(\n    use_label_encoder=False,\n    eval_metric=\"logloss\",\n    n_estimators=810,\n    max_depth=12,\n    learning_rate=0.04122760306111473,\n    subsample=0.9920195260264391,\n    colsample_bytree=0.7260265095394081,\n    colsample_bylevel=0.9989985352864291,\n    colsample_bynode=0.5220381476579743,\n    min_child_weight=4,\n    gamma=0.208214273451558,\n    reg_alpha=2.6398439551213113,\n    reg_lambda=4.145113021798959\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-07T16:52:53.456139Z","iopub.execute_input":"2026-02-07T16:52:53.456448Z","iopub.status.idle":"2026-02-07T16:52:53.474675Z","shell.execute_reply.started":"2026-02-07T16:52:53.456423Z","shell.execute_reply":"2026-02-07T16:52:53.474027Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"lgb_tuned = lgb.LGBMClassifier(\n    objective=\"binary\",\n    verbose=-1,\n    n_estimators=431,\n    max_depth=13,\n    num_leaves=81,\n    learning_rate=0.10150620748447788,\n    subsample=0.7515173871129093,\n    colsample_bytree=0.5869950899621996,\n    min_child_samples=64,\n    reg_alpha=1.6572209442239088,\n    reg_lambda=0.6510034115814697\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-07T16:52:53.475696Z","iopub.execute_input":"2026-02-07T16:52:53.475972Z","iopub.status.idle":"2026-02-07T16:52:53.487826Z","shell.execute_reply.started":"2026-02-07T16:52:53.475953Z","shell.execute_reply":"2026-02-07T16:52:53.487248Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"run_te_cvens_blending(\n    train_data=train_fe,\n    test_data=test_fe,\n    submission_path=\"/kaggle/input/binary-classification-with-a-bank-dataset-clone/sample_submission.csv\",\n    save_path=\"submission.csv\",\n    xgb_model=xgb_tuned,\n    lgb_model=lgb_tuned\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-07T16:52:53.488690Z","iopub.execute_input":"2026-02-07T16:52:53.488958Z","iopub.status.idle":"2026-02-07T17:04:26.665931Z","shell.execute_reply.started":"2026-02-07T16:52:53.488932Z","shell.execute_reply":"2026-02-07T17:04:26.665346Z"}},"outputs":[{"name":"stdout","text":"   fold   roc_auc\n0     1  0.969572\n1     2  0.969739\n2     3  0.970018\n3     4  0.970592\n4     5  0.969795\n5     6  0.970208\n6     7  0.969156\n7     8  0.970076\n8     9  0.969463\n9    10  0.969430\nMean CV Score: 0.96980\n","output_type":"stream"}],"execution_count":15}]}